# name is used in Actions tab of GitHub
# https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#name
name: Deploy Functions

# on is used to specify the event that triggers the workflow
# It's possible to specify multiple events, for example, push and pull_request
# https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#on
on:
  # push is used to trigger the workflow when a commit is pushed to the repository branch
  # https://docs.github.com/ja/actions/using-workflows/events-that-trigger-workflows#push
  push:
    branches:
      # - develop
      # - master
      - 'feature/**' # test
    # Run actions only when changes happens in functions directory
    # https://blog.35d.jp/2020-09-29-github-actions-path
    # paths:
    #   - 'functions/**'

# env is used to set environment variables
# https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#env
env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_DEFAULT_REGION: ap-northeast-1

# jobs is used to define one or more jobs to run in parallel or sequentially
# https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#jobs
jobs:
  # Set the arbitary name of the job
  deploy:
    # runs-on is used to specify the type of machine to run the job
    # Availlable machines are below
    # https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idruns-on
    runs-on: ubuntu-latest
    # steps is used to define a sequence of tasks to be executed by the job
    # Each step is executed in a new process on runner, so the result of previous step's process is not available in the next step
    steps:
      # Set the arbitary name of the step
      # https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#example-using-secrets
      - name: Checkout
        # uses is used to specify the action pre-defined by GitHub or a Docker container to run the step or custom action defined in the same repository
        # https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsuses
        # actions/checkout is a pre-defined action to clone the source code of the repository in the runner to run the following steps
        # @v2, @v3 or @master is used to specify the version of the action. @v2 and @v3 are the major version of the action.
        # @v2 is deprecated, so @v3 is recommended
        # https://github.blog/changelog/2022-09-22-github-actions-all-actions-will-begin-running-on-node16-instead-of-node12/
        uses: actions/checkout@v3

      - name: Test
        run: |
          git log


      # Set the result of the step as an output parameter to use in the next step
      # https://docs.github.com/ja/actions/using-workflows/workflow-commands-for-github-actions#setting-an-output-parameter
      - name: Check if requirements.txt has changed
        id: check_requirements
        # Get the name of the branch using ${{ github.ref_name }} in a run command
        # https://dev.classmethod.jp/articles/how-to-get-a-ref-branch-within-a-workflow-execution-in-github-actions/
        # Github context's content example is below
        # https://docs.github.com/ja/actions/learn-github-actions/contexts#example-contents-of-the-github-context
        # Compare the current merge commit with the HEAD commit of the target branch
        # https://qiita.com/shibukk/items/8c9362a5bd399b9c56be
        # https://qiita.com/shizen-shin/items/ddc0e5bf658bf02fbc3c
        run: |
          if git diff --name-only HEAD^ HEAD -- functions/requirements.txt | grep "requirements.txt"; then
          # if git diff --name-only HEAD^ HEAD | grep "requirements.txt"; then
            echo "SHOULD_UPDATE_LAYER=true" >> "$GITHUB_OUTPUT"
          else
            echo "SHOULD_UPDATE_LAYER=false" >> "$GITHUB_OUTPUT"
          fi

      # Deploy the layer only when requirements.txt has changed
      - name: Set up Python 3.9
        if: steps.check_requirements.outputs.SHOULD_UPDATE_LAYER == 'true'
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      # Save and restore pip packages to reduce the time to install them if requirements.txt has not changed
      # https://github.com/actions/cache#cache-action
      - name: Cache pip packages
        if: steps.check_requirements.outputs.SHOULD_UPDATE_LAYER == 'true'
        # Note: Cache expires in 7 days
        # https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows#usage-limits-and-eviction-policy
        uses: actions/cache@v2
        with:
          # path means the directory to save and restore the cache
          # ~/.cache/pip is the default directory to save packages installed by pip on Ubuntu
          # https://github.com/actions/cache/blob/main/examples.md#python---pip
          path: ~/.cache/pip
          # key is used to save and restore the cache
          # https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows#using-the-cache-action
          # runner.os means the operating system of the runner
          # hashFiles('**/requirements.txt') means the hash value of requirements.txt, so the cache is restored only when requirements.txt has changed
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          # restore-keys is used to find and restore the cache when the key is not found in the cache that have been saved
          # ${{ runner.os }}-pip- must be contained in the keys that have been saved in the caches
          restore-keys: |
            ${{ runner.os }}-pip-

      # pip first checks the local cache and doesn't download packages if they are already stored in the cache directory
      # https://pip.pypa.io/en/stable/topics/caching/
      - name: Install pip packages in python directory
        if: steps.check_requirements.outputs.SHOULD_UPDATE_LAYER == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -t ./functions/python

      # Set up Serverless Framework on Github Actions runner
      # https://github.com/serverless/github-action
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 18
        
      - name: Doctor Serverless Framework
        uses: serverless/github-action@v3.1
        with:
          args: doctor

      # npm ci is unnecessary because the packages are not node_modules in JavaScript but python modules
      # npm ci means that npm install is executed with package-lock.json deleting node_modules before installing packages without resolving　dependencies　of packages and saving them to package-lock.json
      # https://qiita.com/mstssk/items/8759c71f328cab802670
      # - run: npm ci
      - name: Deploy based on Serverless Framework
        uses: serverless/github-action@v3.1
        with:
          args: deploy
        env:
          # Set the name of the stage to deploy based on the branch name using ternary operator
          # https://qiita.com/technote-space/items/cbeed6ddd0488499afaa
          STAGE: ${{ github.ref_name == 'develop' && 'dev' || 'prod' }}

      # sls deploy --config /path/to/serverless.any.yml
      # https://ema-hiro.hatenablog.com/entry/2021/09/19/203541
      # https://www.serverless.com/framework/docs/providers/aws/cli-reference/deploy
      # https://zenn.dev/burizae/articles/c811cae767965a


      # - name: Deploy to Dev
      #   # Using if to specify the condition, only run a step if the condition is met
      #   # https://docs.github.com/ja/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsif
      #   if: contains(toJSON(github.ref), 'develop')
      #   run: |
      #     zip -r functions_dev.zip ./functions -x '*python*'
      #     aws s3 cp ./functions_dev.zip s3://${{ secrets.AWS_S3_TERAKOYA_BUCKET_NAME }}/lambda/booking/
      #     aws lambda update-function-code --function-name terakoya-booking-dev-book --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_dev.zip
      #     aws lambda update-function-code --function-name terakoya-booking-dev-remind --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_dev.zip
      #     aws lambda update-function-code --function-name terakoya-booking-dev-login --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_dev.zip
      #     aws lambda update-function-code --function-name terakoya-booking-dev-book-list --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_dev.zip
      #     aws lambda update-function-code --function-name terakoya-booking-dev-book-edit-place --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_dev.zip

      # - name: Deploy to Prod
      #   if: contains(toJSON(github.ref), 'master')
      #   run: |
      #     zip -r functions_prod.zip ./functions -x '*python*'
      #     aws s3 cp ./functions_prod.zip s3://${{ secrets.AWS_S3_TERAKOYA_BUCKET_NAME }}/lambda/booking/
      #     aws lambda update-function-code --function-name terakoya-booking-prod-book --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_prod.zip
      #     aws lambda update-function-code --function-name terakoya-booking-prod-remind --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_prod.zip
      #     aws lambda update-function-code --function-name terakoya-booking-prod-login --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_prod.zip
      #     aws lambda update-function-code --function-name terakoya-booking-prod-book-list --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_prod.zip
      #     aws lambda update-function-code --function-name terakoya-booking-prod-book-edit-place --s3-bucket terakoya-bucket --s3-key lambda/booking/functions_prod.zip

      #TODO: Manually set a new source code deployed above in settings of each Lambda functions
      # or execute the same number of commands as Lambda Functions like below
      # aws lambda update-function-code --function-name <func_name> --s3-bucket <bucket_name> --s3-key <zip_file_path>
      # aws lambda update-function-code --function-name <func_name> --s3-bucket <bucket_name> --s3-key <zip_file_path>
      # ...
